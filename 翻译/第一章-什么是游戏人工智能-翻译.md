什么是游戏人工智能
===========
作者 Kevin Dill

[toc]

## 1.1介绍

游戏人工只关乎也应该只关乎一件事:让开发者能创作出吸引玩家的体验。我们使用的每种技术，每个技巧，编写的所有代码，都是为此而诞生的。

维基百科上对人工智能的定义是这样的：“对智能代理的研究和设计”[^5]，其中智能代理指的是“一种能感受到周遭环境并采取行动使得目标最大化的系统”。这明显并不是“人工智能”的唯一定义，“人工智能”是个三言两语很难说清的领域，但是这一解释确实准确地描述了大部分时候我们的学校中人工智能研究在研究和教授的内容。本书内我们只会在进行学术性描述的时候才会像普遍上理解的使用这个词。

动画师常常将他们创造的动画角色描述为“生命的幻象”——这个词被认为是华特.迪士尼发明的。动画角色则具有完全不同的目标。动画中的角色完全不需要采取将成功最大化的行为。以动画歪心狼为例,大部分时间角色的动作都是失败的。电影其实是在试图让观众相信这一切都是真的（尽管电影明显是人工制作的），感受那些引人入胜的情节。

每个游戏都不一样，因此对游戏AI的需求也不一样。因此，比起传统的人工智能，游戏人工智能的设计更多地和迪士尼对动画角色的看法具有相同点。就像动画一样，游戏是为了娱乐诞生的；也像动画一样，游戏并不只是关于最大化成功，认知模型，或者真正的智能，而是讲述故事，创造体验，创造“智能的幻觉”（illusion of intelligence）[^1]。

在某些情况下，我们为了创造这种体验所需要的技术可能来自于学术人工智能，但是大部分时候两者还是有很大的差异。我们使用游戏人工智能来表述这些专注于制作智能行为，为观众创造独特体验的技术，而不是创造类似人一样的智能。

## 1.2创造体验

有一种说法，游戏人工智能不是为了最大化成功的机会，而是最大化玩家的乐趣。这确实是游戏人工智能的主要目标，但却可能不是最好的描述。
一方面，乐趣是个难以定义的指标；另一方面，并不是所有游戏都是为了乐趣，有一些游戏是为了讲好故事，有一些则是为了创作激情、冒险、悬疑甚至是恐怖的体验。也有的是为了带给玩家一种能力感，让他们感觉自己像个“重要人物”。

唯一确定的事是，游戏都是为了给玩家创造一种独特的体验——无论这种体验是什么。而游戏人工智能（包括游戏开发中使用的其他技术），就是为了实现这个目标。因此，是否使用某一技术的重要因素是其是否能带来相应的体验，而不是其他任何因素。

### 1.2.1让玩家愿意相信

玩家是非常愿意积极参与到我们为其创造的体验中的。他们愿意沉浸到我们创造的幻境之中，忽视那些明显不和谐的地方。也就是说，提供具有足够吸引力的内容让他们继续沉浸其中是我们的责任。当玩家对待游戏AI给与对应的回应，就好像它们是真实存在的角色一样的时候，我们才算成功了，哪怕这时背后使用的算法逻辑简单到不能再简单。而当AI的行为让玩家想起来AI不过是一段程序的时候，就是我们的失败。ELIZA[^6]，一个由Joeseph Weizenbaum在1964年开发的聊天AI，就是一个两面性例子，向我们展示了用如何简单的算法逻辑就可以获取到玩家的信任，同样的，当算法失效的时候玩家是如何快速地就会失去这种信念。

因为玩家愿意参与到这种体验中来，也因为人们思考的方式，他们其实是具有相当的宽容的。只要AI的行为是基本合情合理的，玩家甚至会主动为AI的决策过程做出解释，玩家的解释甚至可能比实际AI做出决策的原因还要复杂，但却可以让玩家自己信服，甚至听起来非常的合理。事实上，某些情况下构建一个复杂的AI其实是一种错误。除了可能浪费开发者宝贵的时间，也可能导致在AI应该采取合理的行为的时候，采取了与玩家心理预期不符的行为。也就是说，只要当开发者知道，AI实际在“想”什么的时候，AI的行为才是有意义的，当然开发者不可能真正做到这点。这样导致的就是大部分时候AI考虑了各种参数而采取的行为就像是随机产生的，甚至可能做出明显不合时宜的行为。

我们要尽力避免的一种情况就是人工智障——让AI尽力避免采取那些明显错误、没有意义的行为。常见的情况例如AI角色一直对着墙走，或者卡在某些地形，又或者忽视正在对其开枪的玩家。甚至某些在真人玩家身上可能出现的行为也应该被避免，因为这些行为在由AI控制的角色上出现的时候看起来就非常的不真实，例如，真人玩家可能经常会改变他们的想法，目的不定，但是当AI也这样做的时候，只会让人感觉是不是算法出现了错误，而不是AI在重新评估数值。

一种避免人工智障的方法就是编写更好的AI算法，但是玩家对AI的预期都是不同的，大部分时间都很难满足所有的需求。因此，往往采用的都是其他的方案。在一些游戏，例如僵尸游戏就是个很好的例子，僵尸这一类的AI往往被故意设计成比较笨拙，所以玩家反而可以接受它们出现的一些异常行为。还有一些情况下，AI角色会使用一些短语，也被称为信号，来告知玩家它们在做什么。例如，AI士兵可能会大喊“我要投手雷了”，或者“我被击中了”。这些行为并不是在向其他AI交流，（AI间的交流会通过内部代码实现），而只是在向玩家解释它们的行为。有一些游戏（例如模拟人生、动物园大亨）会在角色的头上放上一些图标来表示角色内部的状态。Creature，一个发行了15年以后仍然以其卓越的AI著名的游戏在角色的改变其想法的时候使用问号来向玩家展现这种转变是由角色自己产生的。

### 1.2.2响应性、可控性和随机性

关于众多的架构的讨论以及哪一种最适合游戏AI的讨论已经有很多了。甚至，本书中就有专门的一节也是同样的目的。
一种基于学术性人工智能得出的想法就是基于需要的体验的定义来构建一种启发式的游戏AI，并且通过机器学期来定制化需要的内容。但这种方法存在几个问题，最明显的一种就是这些体验是由游戏设计师（大部分时候他们都不是程序员），用含糊不清，很难被标准描述的文字定义的。如何设计一个启发式的功能来最大化“乐趣”或者“惊喜”或者“炫酷”呢？

这并不是说启发式的AI没有用，事实上，基于效用的AI算法是游戏AI的最常见的一种解决方法，尤其是对那些有着复杂决策需求（例如策略游戏和模拟游戏）的游戏来说。启发式的解决方案是很重要的，然而，为了保持开发者对AI的控制——确保开发者可以调整AI的行为标准（例如难度），来确保营造出需要的体验。如果我们放弃这上面的控制，而把其转交给不确定的机器学习算法，就很难确保获得我们需要的结果。

这是竞争性的需求，然而，我们还是希望我们的角色具有足够的响应性，也就是说，我们希望它可以感受到周遭的环境，并采取适应游戏中时刻细微变动的局势的行动。响应性和可控性并不冲突，你可以构建一个可以响应外界的系统，但是因为你可以控制系统制定决策的时候评估局势的依据，也就保证了系统的可控性。控制响应型的游戏AI比较复杂，然而由于作为开发者你必须仔细思考每一个调节和改变将会如何影响游戏AI的决策过程，而不是简单的直接改变角色的行为。
这个问题并不存在一个简单的解决方案。有一些游戏（例如策略游戏和模拟人生这样的模拟游戏）更多的注重响应性，而一些游戏（例如魔兽世界）更需要可控的决策、更仔细设计的AI来为玩家提供预期的体验。没有哪一方是错的。每种类型都有很好的游戏作为例子，然而它们传递的游戏体验却是不一样的，因此这是在选择你的游戏AI解决方案时必须要考虑的。

![表1.1](https://cdn.sunsi.club/2021-03-13/2-Gz8V.webp)

有很多流行的游戏AI架构，其中许多类型在之后的章节中会被仔细讨论，有一些更注重响应性，而一些可控性会更强一些。表1.1根据可控性的权衡对如今最流行的游戏AI架构做出了简单的排列。要记住，每种架构都有自己独特的优点、缺点和特性，这个表只是作为一个简单的参考。

注意，把机器学习放进图中只是因为它在学术领域的流行性，现在很少有游戏利用机器学习来作为其核心的游戏AI架构。同样的，在慎重地考虑后行为树并没有被放进这张图中，因为行为树的表现很大程度上取决于决策组件使用的类型，如果这些组件都是很简单的，例如如Damian Isla设想的[^3]那样，此时的决策树更像有限状态机。然而决策树最厉害的地方就在于每个节点都可以包含最适合的决策，使你可以对每个决策的决策都使用最适合的架构。

另一个选择架构时应该考虑的因素是随机性。对于许多游戏来说，我们想要为我们的角色增加适当的随机性，以便它们的行为不会被轻易地预测，并被玩家利用。同时，我们也不希望角色采取那些明显不对的行为，所以我们需要确保AI的随机行为是有意义的。有一些架构就很利于向其中添加随机性（尤其是，行为树和基于效用的AI处理随机性处理得很好），这是你在设计自己的游戏的时候可能需要考虑的另一个因素。

### 1.2.3简单易用和可扩展性

对于可控性和人工智障的避免都需要游戏AI的配置是可重复的过程，配置游戏AI以确保其可以应对每种会出现的情况，或者说大部分可能会出现的情况，可以执行开发者的意图，每种情况都像现实一样做出可信的行为是不可能实现的。因此，对AI进行重复的测试，找出最糟糕的情况，改进并再次测试是必要的。

Brian Kernighan，Unix系统和C语言的发明者就相信，“调试比写代码还要难，如果你把代码写得尽可能地清晰，那么就越难调试”[^4]。这句话对于游戏AI来说甚至加倍了。对于代码的任何更改都有着不确定的边际效应，也就是说，每次你修好了一个Bug或者调整了一个平衡问题，可能会在其他地方造成一个更加难以察觉的问题。更简单的底层算法意味着你可以记住关于AI的更多整体细节，因此每次更改的时候你可以更全面地意料到可能会造成的影响，你的修改和开发也会更安全和迅速，最终的成果也可能更加完善。

如果你研究这些普遍在游戏种使用的决策算法-有限状态机，脚本，行为树，基于权重的随机行为，甚至基于目标的行为规划，这些算法本身其实是非常简单的，反而是在这些框架之上进行的配置可能会非常复杂，但是底层的代码仍然是非常简单的，易于理解，易于追踪和调试。

注意，许多简单的算法（有限状态机就是典型的例子）在AI的复杂程度增加的时候很难处理。例如有限状态机，增加常数个状态的时候，状态间的切换的复杂度却可能以幂级数增加。很明显，随着状态的增加，状态机很快就变得很难处理。因此，一种真正优雅的架构应该不仅简单易懂，还应该易于使用，不论是小规模的使用还是处理复杂的情况，也就是说，应该易于扩展。

#### 1.2.4小技巧和“作弊”

一定要慎重地让AI在游戏中作弊。但是很明显关于什么是作弊我们并不能得出统一的结论。让AI角色比玩家角色数值更高一点算作弊吗？如果我们给与它们一种修正额外奖励的道具呢？在策略游戏中给AI一些经济补助，让它们可以更便宜地生产单位算作弊吗？如果让玩家可以选择额外奖励地数量，把这叫做难度选择呢？

有一个关于这的很好的例子，这是我最近在和Bob Fitch，暴雪公司的策略游戏游戏AI负责人，聊天的时候知道的[^ 2 ]。表面上，魔兽世界中的场景AI会等待一段固定的时间，然后开始生成一波怪物来攻击玩家，会在场景边缘的灰色雾气中生成怪物。也就是说，正好在玩家的可视范围之外，AI会不断生成怪物直到玩家的防御工事差不多快损坏。然后AI就会停止生成怪物，让玩家把仍然活着的怪物消灭之后，获得胜利。

这种方法好像就是明显的作弊，让AI不必担心如何建造建筑，不必担心金钱，或者如何招募单位，它可以生成所有需要的单位。另一方面，这样的设计也造成了，无论玩家水平如何，都可以体验到一场史诗般的战斗——一场你绝对会达到极限，竭尽所能，但是最终击败所有敌人，获得胜利的战斗。
当然，这样的“作弊”也会有明显的坏处，只有当玩家对此一无所知时这种方法才奏效。如果玩家一开始就知道游戏开发者要做的事，就会完全是另外一种体验——没有人喜欢被如此愚弄。不幸的是，近年来。随着互联网的发展，比起1994年，玩家变得更难糊弄，也更加不宽容。

另外一种类型的作弊只是单纯情报上的，例如，AI为了知道一个单位是否存在，以及其位置，它必须要感知到这个单位吗？问题是，做视线检测来检查可见性是很简单的。但是记住所见并且以此预测接下来的事情则更加复杂。换一种说法，如果AI看见了一个单位，但是紧接着这个单位走出了AI的视野范围，AI应该仍然记住其存在吗？如何猜测其可能的位置？如果见到了同一类型的单位两次，如何知道它们是否是同一单位还是不同的呢？人类很擅长处理这类问题，但要做好这些，需要对象建模，直觉和纯粹猜测的充分利用，但这些都是计算机不擅长的。
不幸的是，对于许多类型的游戏来说，AI对于如资源位置、敌人力量和位置的预测都是非常重要的的。如果玩家预测这些信息失败，可能会输掉游戏，但是大多数玩家对此都是可以接受的，“我只是没找到啥可以用的”，“你只是这次运气好，下一次就不一定了”，玩家们通常会这样说，然后再来一局，或者读取存档。而如果AI做得不好，玩家就会赢得非常轻松，感受不到任何的挑战性。他们不会想“AI或许只是运气不好”，而只会想“天，这个AI也太笨了”。一旦他们这样开始看待AI，游戏开发者的目标就算失败了。

最后，让AI作弊与否其实很好决定，如果这样做可以提升玩家的体验，那就作弊，但是记住如果玩家发现AI在作弊，情况就会大不一样，并且往往带来糟糕的局面。在可汗2，一个因为其AI系统备受赞赏的实时战略游戏中，AI就做了两个小小的弊。一开始探索的时候，我们大约每30秒给AI一个机会作弊让其探索一个一定会有收获的区域，这避免了AI单纯的没有找到任何有用的资源的情况；第二个保持AI的大概的总实力和附件的敌人的实力接近，而不是具体的单位。这使我们可以为我们攻击和防御的目标设置合理的数量，避免没有意义的兵力部署。没有评论家发现这些作弊，事实上他们以为的许多智能的行为，其实就是我们上面提到的，作弊带来的影响。

## 1.3结论

学术AI包含许多内容，可以是解决实际的问题，重现人类智能，对人类认知模型进行建模，以便学习研究我们的大脑是如何工作的，优化复杂交互环境中的表现（例如，自动机器）或者其他所有具有挑战性的值得追求的目标。所有这些任务都是比较困难、具有意义的，但是这些问题的解决方案并不同样适用于游戏。

游戏AI应该也只应该与一件事相关：赋予开发者为玩家创造具有吸引力的体验，一种让玩家愿意花费时间游玩游戏，愿意购买额外内容包和游戏续作的体验，如果你成功了的话。



## 注释

[^1]: E. Adams. “Putting the Ghost in the Machine.” Lecture, 1999 American Association for Artificial Intelligence Symposium on Computer Games and AI, 1999.
[^2]:  B. Fitch. “Evolution of RTS AI.” Lecture, 2011 AI and Interactive Digital Entertainment Conference, 2011. 
[^3]: D. Isla. “Handling complexity in the Halo 2 AI.” 2005 Game Developer’s Conference, 2005. Available online (http://www.gamasutra.com/view/feature/130663/gdc_2005_ proceeding_handling_.php). 
[^4]: B. Kernighan. Original source unknown. Available online (http://www.softwarequotes.com/printableshowquotes.aspx?id = 575). 
[^5]: Wikipedia. “Artificial Intelligence.” Available online (http://en.wikipedia.org/ wiki/Artificial_intelligence, 2012). 
[^6]: Wikipedia. “ELIZA.” Available online (http://en.wikipedia.org/wiki/ELIZA, 2012).
